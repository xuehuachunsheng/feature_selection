package ufs.cluster.evaluate;

import java.io.FileReader;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;

import org.ujmp.core.Matrix;
import org.ujmp.core.calculation.Calculation.Ret;

import ufs.cluster.evaluate.impl.Hungary;
import ufs.utils.Utils;
import weka.core.Instances;

/**
 * Some evaluating algorithms for a cluster always consider the label of a pair
 * of samples, such as Jaccard Coefficient (JC), Fowlkes and Mallows Index (FMI)
 * and Rand Index (RI), all of which are outer indices. Some others consider the
 * cluster's partition and the distance of two samples, such as Davies-Bouldin
 * Index (DBI) and Dunn Index (DI), all of which are inner indices. There are
 * some basic algorithms for evaluating the performance of a cluster. See
 * <bold>Machine Learning(ZhiHua. Zhou, P198)</bold> for more detail.
 * 
 * Author: Wyx <br>
 * Date: Dec.12, 2016~Dec.13, 2016 <br>
 * Progress: Done. <br>
 * Note: You need to import UJMP jar to use this class
 * 
 */
public class ClusterEvaluate {

	/**
	 * It is assumed that h_i, h_i* represents the class label of the i'th
	 * sample(x_i) given by the model of cluster and the real, respectively. we
	 * assign
	 * 
	 * <pre>
	 * 	a = |SS|, SS = {(x_i, x_j) | h_i = h_j, h_i* = h_j*, i < j}
	 *  b = |SD|, SD = {(x_i, x_j) | h_i = h_j, h_i* != h_j*, i < j}
	 *  c = |DS|, DS = {(x_i, x_j) | h_i != h_j, h_i* = h_j*, i < j}
	 *  d = |DD|, DD = {(x_i, x_j) | h_i != h_j, h_i* != h_j*, i < j}
	 * </pre>
	 * 
	 * These variables are used in JC, FMI and RI.
	 */
	int a, b, c, d;

	/**
	 * Predict and real labels. The length of this variable must be equal with
	 * each other.
	 */
	int[] predictLabels, realLabels;

	/**
	 * The data. X ∈ R^(n×d), where n is the number of samples and d is the
	 * number of dimension of each sample.
	 */
	// Matrix X;

	/**
	 * The centerIndices of predict clusters. centerIndices stores those center indices in
	 * X. It is used in DBI. We assume that C_i is the cluster represented by
	 * centerIndices[i].
	 */
	int[] centerIndices;

	/**
	 * The centers. i-th row of it is the i-th center.
	 */
	Matrix centers;
	
	/**
	 * The average distance in each cluster. avgC[i] stores the average distance
	 * of the cluster corresponding to those whom labels are equals to sample
	 * located at centerIndices[i]. This variable is computed by given X,
	 * predictLabels and centerIndices. It is used in DBI.
	 * 
	 * We assign
	 * 
	 * <pre>
	 * 	avgC[i] = 2*(Sum_{1<=j<k<=C_i} dist(x_j, x_k)) / (|C_i|*(|C_i| - 1))
	 * </pre>
	 * 
	 * It is a row vector.
	 */
	Matrix avgC;

	/**
	 * The distance among those centerIndices. dCen[i][j] stores the distance between
	 * the samples located in centerIndices[i] and center[j]. Obviously, it is a
	 * symmetric matrix. It is used in DBI.
	 * 
	 * We assign
	 * 
	 * <pre>
	 * dCen[i][j] = dist(x_centerIndices[i], x_centerIndices[j])
	 * </pre>
	 */
	Matrix dCen;

	/**
	 * The diameter of each cluster. diamC[i] stores the diameter (Farthest
	 * distance of two samples) of the cluster corresponding to those whom
	 * labels are equals to sample located at centerIndices[i]. This variable is
	 * computed by given X, predictLabels and centerIndices. It is used in DI.
	 * 
	 * We assign
	 * 
	 * <pre>
	 * 	diamC[i] = max_{1<=j<k<=|C_i|} dist(x_j, x_k)
	 * </pre>
	 * 
	 * It is a row vector.
	 */
	Matrix diamC;

	/**
	 * The minimum distance of two samples in two different clusters. Likewise,
	 * dMin[i][j] stores the minimum distance between two samples located in C_i
	 * and C_j, respectively.
	 * 
	 * We assign
	 * 
	 * <pre>
	 * 	dMin[i][j] = min_{x_i ∈ C_i, x_j ∈ C_j} dist(x_i, x_j)
	 * </pre>
	 * 
	 * It is also a symmetric matrix.
	 */
	Matrix dMin;

	/**
	 * The coefficient matrix is generated by the intersection of each predict
	 * cluster and real cluster. It is used in finding max matching for
	 * bipartite graph. The element in i-th row and j-th column represents that
	 * the size of intersection set of i-th predict cluster and the j-th real
	 * cluster.
	 */
	Matrix coefficientMatrix;

	/**
	 * Construct a cluster evaluater and assign a, b, c and d. The two
	 * parameters must be length-equal. By using this constructor, you can use
	 * JC, FMI and RI. Note that we do not deal the exception. Both the predict
	 * and real labels must be started from 0, that is, 0 is the first cluster.
	 * 
	 * @param pPredictLabels
	 *            The predictive labels of a group of samples.
	 * @param pRealLabels
	 *            The real labels of the group of samples.
	 */
	public ClusterEvaluate(int[] pPredictLabels, int[] pRealLabels) {
		outerIndicesParamConst(pPredictLabels, pRealLabels);

		// Find a max matching for bipartite graph.
		coefficientMatrixGenerated(pPredictLabels, pRealLabels);
	}// End of constructor

	private void outerIndicesParamConst(int[] pPredictLabels, int[] pRealLabels) {
		predictLabels = pPredictLabels;
		realLabels = pRealLabels;
		int tA = 0, tB = 0, tC = 0, tD = 0;
		for (int i = 0; i < realLabels.length; i++) {
			for (int j = i + 1; j < realLabels.length; j++) {
				if (pPredictLabels[i] == pPredictLabels[j]) {
					if (pRealLabels[i] == pRealLabels[j]) {
						tA++;
					} else {
						tB++;
					}
				} else {
					if (pRealLabels[i] == pRealLabels[j]) {
						tC++;
					} else {
						tD++;
					}
				} // Of if
			} // Of for j
		} // Of for i
		a = tA;
		b = tB;
		c = tC;
		d = tD;
	}

	/**
	 * This method constructs the coefficient matrix to compute max matching for
	 * bipartite graph
	 * 
	 * @param pPredictLabels
	 * @param pRealLabels
	 */
	private void coefficientMatrixGenerated(int[] pPredictLabels,
			int[] pRealLabels) {
		// Record the number of clusters.
		Set<Integer> tSet = new HashSet();
		Set<Integer> tSet2 = new HashSet();
		for (int i = 0; i < pPredictLabels.length; i++) {
			tSet.add(pPredictLabels[i]);
			tSet2.add(pRealLabels[i]);
		}
		// Construct clusters
		Set<Integer>[] predictClusterIndices = new HashSet[tSet.size()];
		Set<Integer>[] realClusterIndices = new HashSet[tSet2.size()];
		for (int i = 0; i < predictClusterIndices.length; i++) {
			predictClusterIndices[i] = new HashSet<>();
			realClusterIndices[i] = new HashSet<>();
		}
		for (int i = 0; i < pPredictLabels.length; i++) {
			predictClusterIndices[pPredictLabels[i]].add(i);
			realClusterIndices[pRealLabels[i]].add(i);
		}
		int maxCluster = Math.max(predictClusterIndices.length,
				realClusterIndices.length);
		Matrix tCoefficientMatrix = Matrix.Factory.zeros(maxCluster,
				maxCluster);

		for (int i = 0; i < predictClusterIndices.length; i++) {
			for (int j = 0; j < realClusterIndices.length; j++) {
				Set<Integer> tSet3 = new HashSet<>();
				tSet3.addAll(predictClusterIndices[i]);
				tSet3.retainAll(realClusterIndices[j]);
				tCoefficientMatrix.setAsDouble(tSet3.size(), i, j);
			}
		}
		coefficientMatrix = tCoefficientMatrix;
	}

	/**
	 * Construct a cluster evaluater and compute avgC, diamC, dMin, dCen. By
	 * using this constructor, you can use DBI and DI. Note. we do not deal the
	 * exception.
	 * 
	 * @param pX
	 *            The data. Each line is a sample. In fact, we do not use the
	 *            original samples.
	 * @param pDistX
	 *            It is a R^(n*n) matrix that stores the distance between x_i
	 *            and x_j located in i'th row and j'th column. Obviously, it is
	 *            a symmetric matrix.
	 * @param pPredictLabels
	 *            The predict labels.
	 * @param pCenterIndices
	 *            The centerIndices of predict clusters. pCenterIndices stores those center
	 *            indices in X.
	 */
	public ClusterEvaluate(/* Matrix pX, */Matrix pDistX,
			int[] pPredictLabels, int[] pCenterIndices) {
		innerIndicesParamConst(pDistX, pPredictLabels, pCenterIndices);
	}
	private void innerIndicesParamConst(/* Matrix pX, */Matrix pDistX,
			int[] pPredictLabels, int[] pCenterIndices) {
		// X = pX;
		predictLabels = pPredictLabels;
		centerIndices = pCenterIndices;

		Map<Integer, List<Integer>> map = new HashMap<>();

		for (int i = 0; i < pCenterIndices.length; i++) {
			List<Integer> list = new ArrayList<>();
			map.put(pCenterIndices[i], list);
		}

		for (int i = 0; i < pPredictLabels.length; i++) {
			for (int j = 0; j < pCenterIndices.length; j++) {
				if (pPredictLabels[i] == pPredictLabels[pCenterIndices[j]]) {
					map.get(pCenterIndices[j]).add(i);
					break;
				}
			}
		}

		// Compute avgC, dimC, dMin, and dCen
		Matrix tAvgC = Matrix.Factory.zeros(1, pCenterIndices.length);
		Matrix tDiamC = Matrix.Factory.zeros(1, pCenterIndices.length);
		Matrix tDMin = Matrix.Factory.zeros(pCenterIndices.length, pCenterIndices.length);
		Matrix tDCen = Matrix.Factory.zeros(pCenterIndices.length, pCenterIndices.length);
		for (int i = 0; i < pCenterIndices.length; i++) {
			Integer[] indices = map.get(pCenterIndices[i]).toArray(new Integer[0]);
			double tDiamCi = Double.MIN_VALUE;
			double tSumDist = 0;
			for (int j = 0; j < indices.length; j++) {
				for (int k = j + 1; k < indices.length; k++) {
					double tDist = pDistX.getAsDouble(indices[j], indices[k]);
					tSumDist += tDist;
					if (tDiamCi < tDist) {
						tDiamCi = tDist;
					}

				}
			}
			tAvgC.setAsDouble(indices.length == 1 ? 0 : tSumDist * 2
					/ (indices.length * (indices.length - 1)), 0, i);
			tDiamC.setAsDouble(tDiamCi, 0, i);
			for (int j = i + 1; j < pCenterIndices.length; j++) {
				Integer[] _indices = map.get(pCenterIndices[j]).toArray(
						new Integer[0]);
				double tDMinDist = Double.MAX_VALUE;
				for (int k = 0; k < indices.length; k++) {
					for (int m = 0; m < _indices.length; m++) {
						if (tDMinDist > pDistX.getAsDouble(indices[k],
								_indices[m])) {
							tDMinDist = pDistX.getAsDouble(indices[k],
									_indices[m]);
						}
					}
				}
				tDMin.setAsDouble(tDMinDist, i, j);
				tDMin.setAsDouble(tDMinDist, j, i);
				tDCen.setAsDouble(pDistX.getAsDouble(pCenterIndices[i], pCenterIndices[j]),
						i, j);
				tDCen.setAsDouble(pDistX.getAsDouble(pCenterIndices[i], pCenterIndices[j]),
						j, i);
			}
		}
		avgC = tAvgC;
		dMin = tDMin;
		diamC = tDiamC;
		dCen = tDCen;
	}
	
	/**
	 * Construct a cluster evaluater and compute avgC, diamC, dMin, dCen. By
	 * using this constructor, you can use DBI and DI. Note. we do not deal the
	 * exception.
	 * 
	 * @param pX
	 *            The data. Each line is a sample. In fact, we do not use the
	 *            original samples.
	 * @param pDistX
	 *            It is a R^(n*n) matrix that stores the distance between x_i
	 *            and x_j located in i'th row and j'th column. Obviously, it is
	 *            a symmetric matrix.
	 * @param pPredictLabels
	 *            The predict labels.
	 * @param pCenterIndices
	 *            The center samples.
	 */
	public ClusterEvaluate(/* Matrix pX, */Matrix pDistX,
			int[] pPredictLabels, Matrix pCenters) {
		innerIndicesParamConst(pDistX, pPredictLabels, pCenters);
	}
	
	private void innerIndicesParamConst(/* Matrix pX, */Matrix pDistX,
			int[] pPredictLabels, Matrix pCenters) {
		// X = pX;
		predictLabels = pPredictLabels;
		centers = pCenters;
		int numCenters = (int) pCenters.getRowCount();
		// <ClusterIndex, List<Integer>>
		Map<Integer, List<Integer>> map = new HashMap<>();
		
		for (int i = 0; i < numCenters; i++) {
			List<Integer> list = new ArrayList<>();
			map.put(i, list);
		}

		for (int i = 0; i < pPredictLabels.length; i++) {
			map.get(pPredictLabels[i]).add(i);
		}

		// Compute avgC, dimC, dMin, and dCen
		Matrix tAvgC = Matrix.Factory.zeros(1, numCenters);
		Matrix tDiamC = Matrix.Factory.zeros(1, numCenters);
		Matrix tDMin = Matrix.Factory.zeros(numCenters, numCenters);
		Matrix tDCen = Matrix.Factory.zeros(numCenters, numCenters);
		for (int i = 0; i < numCenters; i++) {
			Integer[] indices = map.get(i).toArray(new Integer[0]);
			double tDiamCi = Double.MIN_VALUE;
			double tSumDist = 0;
			for (int j = 0; j < indices.length; j++) {
				for (int k = j + 1; k < indices.length; k++) {
					double tDist = pDistX.getAsDouble(indices[j], indices[k]);
					tSumDist += tDist;
					if (tDiamCi < tDist) {
						tDiamCi = tDist;
					}
				}
			}
			tAvgC.setAsDouble(indices.length == 1 ? 0 : tSumDist * 2
					/ (indices.length * (indices.length - 1)), 0, i);
			tDiamC.setAsDouble(tDiamCi, 0, i);
			for (int j = i + 1; j < numCenters; j++) {
				Integer[] _indices = map.get(j).toArray(
						new Integer[0]);
				double tDMinDist = Double.MAX_VALUE;
				for (int k = 0; k < indices.length; k++) {
					for (int m = 0; m < _indices.length; m++) {
						if (tDMinDist > pDistX.getAsDouble(indices[k],
								_indices[m])) {
							tDMinDist = pDistX.getAsDouble(indices[k],
									_indices[m]);
						}
					}
				}
				tDMin.setAsDouble(tDMinDist, i, j);
				tDMin.setAsDouble(tDMinDist, j, i);
				// We use the norm 2 to compute the distance
				double tDistance = pCenters.selectRows(Ret.NEW, i).minus(pCenters.selectRows(Ret.NEW, j)).normF();
				tDCen.setAsDouble(tDistance,
						i, j);
				tDCen.setAsDouble(tDistance,
						j, i);
			}
		}
		avgC = tAvgC;
		dMin = tDMin;
		diamC = tDiamC;
		dCen = tDCen;
	}

	/**
	 * Construct a cluster evaluater and compute avgC, diamC, dMin, dCen. By
	 * using this constructor, you can use both outer and inner indices. Note.
	 * we do not deal with the exception.
	 * 
	 * @param pX
	 *            The data. Each line is a sample. In fact, we do not use the
	 *            original samples.
	 * @param pDistX
	 *            It is a R^(n*n) matrix that stores the distance between x_i
	 *            and x_j located in i'th row and j'th column. Obviously, it is
	 *            a symmetric matrix.
	 * @param pPredictLabels
	 *            The predict labels.
	 * @param pCenterIndices
	 *            The centerIndices of predict clusters. pCenterIndices stores those center
	 *            indices in X.
	 */
	public ClusterEvaluate(Matrix pDistX, int[] pPredictLabels, int[] pCenterIndices,
			int[] pRealLabels) {
		outerIndicesParamConst(pPredictLabels, pRealLabels);
		innerIndicesParamConst(pDistX, pPredictLabels, pCenterIndices);
	}

	/**
	 * Jaccard Coefficient. In [0, 1], the greater, the better.
	 * 
	 * We assign
	 * 
	 * <pre>
	 * jc = a / (a + b + c)
	 * </pre>
	 */
	public double jc() {
		return (a + 0.0) / (a + b + c);
	}

	/**
	 * Fowlkes and Mallows Index (FMI). In [0, 1], the greater, the better.
	 * 
	 * We assign
	 * 
	 * <pre>
	 * fmi = √(a^2/((a+b)*(a+c)))
	 * </pre>
	 * 
	 * @return
	 */
	public double fmi() {
		return Math.sqrt(a * a / ((a + b + 0.0) * (a + c)));
	}

	/**
	 * Rand Index (RI). In [0, 1], the greater, the better. We assign
	 * 
	 * <pre>
	 * ri = 2(a+d) / (m*(m-1)), m is the number of samples.
	 * </pre>
	 * 
	 */
	public double ri() {
		return realLabels.length == 1 ? 0 : 2.0 * (a + d)
				/ (realLabels.length * (realLabels.length - 1));
	}

	/**
	 * Davies-Bouldin Index. the lesser, the better.
	 * 
	 * We assign
	 * 
	 * <pre>
	 * dbi = 1 / k * Sum_{i = 1 to k} max_{j != i} ((avg(C_i) + avg(C_j)) / dCen(C_i, C_j)), 
	 * where k is the number of clusters.
	 * </pre>
	 * 
	 */
	public double dbi() {
		double tDBI = 0;
		for (int i = 0; i < centerIndices.length; i++) {
			double tMax = Double.MIN_VALUE;
			for (int j = 0; j < centerIndices.length; j++) {
				double tValue = (avgC.getAsDouble(0, i) + avgC
						.getAsDouble(0, j)) / dCen.getAsDouble(i, j);
				if (j != i && tMax < tValue) {
					tMax = tValue;
				}
			}
			tDBI += tMax;
		}
		return tDBI / centerIndices.length;
	}

	/**
	 * Dunn Index. the greater, the better. We assign
	 * 
	 * <pre>
	 * di = min_{1<=i<=k} [ min_{j != i} (dMin(C_i, C_j) / max_{1<=p<=k} diam(C_p)) ]
	 * </pre>
	 */
	public double di() {
		double tDI = Double.MIN_VALUE;
		double tMaxDiam = diamC.max(Ret.NEW, Matrix.ALL).getAsDouble(0, 0);
		for (int i = 0; i < centerIndices.length; i++) {
			for (int j = i + 1; j < centerIndices.length; j++) {
				if (tDI < dMin.getAsDouble(i, j)) {
					tDI = dMin.getAsDouble(i, j);
				}
			}
		}
		return tDI / tMaxDiam;
	}

//	/**
//	 * The accuracy obtained by Hungarian method. The Hungarian method solves
//	 * the 0-1 programming problems as follows
//	 *
//	 * <pre>
//	 * 			min z = \sum_{i=1}^n \sum_{j=1}^n c_{ij} x_{ij}
//	 * 
//	 * 			s.t. \sum{i=1}^n x_{ij} = 1,  j = 1, ..., n
//	 * 				 \sum{j=1}^n x_{ij} = 1,  i = 1, ..., n
//	 * 				 x_{ij} = 0 or 1,         i, j = 1, ..., n
//	 * </pre>
//	 * 
//	 * In fact, it finds a max matching for bipartite graph.
//	 * 
//	 * @return acc.
//	 */
//	public double acc() {
//		Matrix M = Matrix.Factory.fill(coefficientMatrix.max(Ret.NEW, Matrix.ALL).getAsInt(0, 0), coefficientMatrix.getRowCount(), coefficientMatrix.getColumnCount());
//		Matrix tMatrix = M.minus(coefficientMatrix);
//		double[][] matchingResult = tMatrix.toDoubleArray();
//		Hungary.appoint(matchingResult);
//		double sum = 0;
//		for (int i = 0; i < matchingResult.length; i++) {
//			for (int j = 0; j < matchingResult.length; j++)
//				if (matchingResult[i][j] == -1) {
//					sum += coefficientMatrix.getAsDouble(i, j);
//					break;
//				}
//		}
//		
//		return sum / coefficientMatrix.getRowCount();
//	}

	@Override
	public String toString() {
		return "ClusterEvaluate [a=" + a + ", b=" + b + ", c=" + c + ", d=" + d
				+ ", \r\navgC=" + avgC + ", \r\ndCen=" + dCen + ", \r\ndiamC="
				+ diamC + ", \r\ndMin=" + dMin + "]";
	}

	/**
	 * Testing.
	 */
	public static void main(String[] args) throws Exception {
		
		
		// Input
		Instances instances = new Instances(new FileReader("src/data/arff/iris.arff"));
		instances.setClassIndex(instances.numAttributes()-1);
		
		int[] predictLabels = new int[]{
				1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,
				2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,
				3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3
		};
		
		// center indices
		int[] centerIndices = { 17, 63, 133 };
		// End Input
		
		// Process
		Matrix xMatrix = Utils.instancesToMatrixWithLabel(instances);
		
		int d = (int)xMatrix.getColumnCount();
		long[] dataColumn = new long[d];
		for (int i = 0; i < d; i++) {
			dataColumn[i] = i;
		}
		Matrix X = xMatrix.selectColumns(Ret.NEW, dataColumn);
		
		Matrix labels = xMatrix.selectColumns(Ret.NEW, d-1);
		
//		// Samples
//		Matrix X = Matrix.Factory.zeros(8, 2);
//		{
//			X.setAsDouble(1, 0, 0);
//			X.setAsDouble(1, 0, 1);
//
//			X.setAsDouble(1.1, 1, 0);
//			X.setAsDouble(2, 1, 1);
//
//			X.setAsDouble(2, 2, 0);
//			X.setAsDouble(1.1, 2, 1);
//
//			X.setAsDouble(3, 3, 0);
//			X.setAsDouble(3, 3, 1);
//
//			X.setAsDouble(2.9, 4, 0);
//			X.setAsDouble(4, 4, 1);
//
//			X.setAsDouble(3.1, 5, 0);
//			X.setAsDouble(4, 5, 1);
//
//			X.setAsDouble(5, 6, 0);
//			X.setAsDouble(1.1, 6, 1);
//
//			X.setAsDouble(5.5, 7, 0);
//			X.setAsDouble(1.1, 7, 1);
//
//		}

		// Distance Matrix
		Matrix distX = X.euklideanDistance(Ret.NEW, false);
		// Real labels
//		int[] realLabels = { 0, 0, 0, 1, 1, 1, 2, 2 };
		// int[] predictLabels = { 0, 0, 0, 1, 1, 1, 2, 2 };
		

		// Outer Index Evaluating
//		ClusterEvaluate clusterEvaluate = new ClusterEvaluate(predictLabels,
//				realLabels);
//
//		System.out.println("a=" + clusterEvaluate.a);
//		System.out.println("b=" + clusterEvaluate.b);
//		System.out.println("c=" + clusterEvaluate.c);
//		System.out.println("d=" + clusterEvaluate.d);
//
//		System.out.println("JC=" + clusterEvaluate.jc());
//		System.out.println("FMI=" + clusterEvaluate.fmi());
//		System.out.println("RI=" + clusterEvaluate.ri());

		// Inner Index Evaluating
		
		ClusterEvaluate clusterEvaluate = new ClusterEvaluate(distX, predictLabels, centerIndices);

//		System.out.println("Distance Matrix: \r\n" + distX);
		System.out.println("avgC: \r\n" + clusterEvaluate.avgC);

		System.out.println("diamC: \r\n" + clusterEvaluate.diamC);

		System.out.println("dMin: \r\n" + clusterEvaluate.dMin);

		System.out.println("dCen: \r\n" + clusterEvaluate.dCen);
		// Output
		System.out.println("DBI: \r\n" + clusterEvaluate.dbi());
		
		System.out.println("DI: \r\n" + clusterEvaluate.di());
	}
}
